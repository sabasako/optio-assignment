# ჩანაწერების დამუშავების სისტემა (Record Processing System)

## პროექტის აღწერა

ეს არის Microservice სისტემა, რომელიც უზრუნველყოფს მონაცემების დამუშავებას მასშტაბურად. სისტემა იყენებს microservices არქიტექტურას და აერთიანებს შემდეგ ტექნოლოგიებს:

- **NestJS** - backend framework
- **RabbitMQ** - შეტყობინებების რიგი (message queue)
- **Redis** - cache და state management
- **Elasticsearch** - მონაცემების შენახვა და ძიება
- **Kibana** - მონაცემების ვიზუალიზაცია
- **Angular** - frontend აპლიკაცია
- **WebSocket** - რეალურ დროში მონაცემების გაცვლა

## სისტემის არქიტექტურა

სისტემა შედგება შემდეგი სერვისებისგან:

1. **API Gateway** - მთავარი შესასვლელი წერტილი, რომელიც იღებს HTTP მოთხოვნებს
2. **Scheduler Service** - Redis-ში ინახავს და გეგმავს ჩანაწერებს, შემდეგ კი განსაზღვრული სიჩქარით აგზავნის მათ RabbitMQ-ში.
3. **Worker Services (2 ინსტანსი)** - იღებენ და ამუშავებენ ჩანაწერებს RabbitMQ-დან
4. **WebSocket Service** - რეალურ დროში უგზავნის პროგრესის ინფორმაციას frontend-ს
5. **Frontend** - Angular აპლიკაცია job-ების მართვისთვის

## პროექტის სტრუქტურა

პროექტი აგებულია NestJS Monorepo პრინციპით, რაც საშუალებას გვაძლევს, ერთ რეპოზიტორიაში ვმართოთ რამდენიმე დაკავშირებული აპლიკაცია (Microservices). ძირითადი დირექტორიებია:

    /apps: ეს არის მთავარი დირექტორია, სადაც პროექტის ყველა მიკროსერვისი (api-gateway, scheduler-service, worker-service, websocket-service). თითოეული მათგანი წარმოადგენს დამოუკიდებელ, გაშვებად აპლიკაციას.

    /frontend: აქ არის angular ის აპლიკაცია

    /libs: ეს დირექტორია შეიცავს საერთო ლოგიკასა და მოდულებს, რომლებიც შეიძლება გაზიარდეს რამდენიმე მიკროსერვისს შორის. ეს გვეხმარება თავიდან ავირიდოთ კოდის დუბლირება და უზრუნველყოფს ერთგვაროვან მიდგომას საერთო ამოცანების გადაჭრისას.

## როგორ გავუშვათ სისტემა

### წინაპირობები

დარწმუნდით, რომ თქვენს სისტემაზე დაინსტალირებულია:

- **Docker** (20.10 ან უფრო ახალი ვერსია)
- **Docker Compose** (v2.0 ან უფრო ახალი ვერსია)

### 1. რეპოზიტორიის კლონირება

```bash
git clone https://github.com/sabasako/optio-assignment
cd optio-assignment
```

### 2. გარემოს კონფიგურაცია

შექმენით \`.env\` ფაილი \`.env.example\`-ის საფუძველზე:

```bash
cp .env.example .env
```

### 3. სისტემის გაშვება

მთელი სისტემის ერთი ბრძანებით გაშვება:

```bash
docker compose up --build
```

ან, თუ გსურთ background-ში გაშვება:

```bash
docker compose up --build -d
```

### 4. შემოწმება რომ ყველა სერვისი გაშვებულია

```bash
docker compose ps
```

ყველა სერვისი უნდა იყოს \`healthy\` ან \`started\` სტატუსში.

### 5. დაშვების პორტები

სისტემის გაშვების შემდეგ, შემდეგი სერვისები იქნება ხელმისაწვდომი:

- **Frontend**: http://localhost:4200
- **API Gateway**: http://localhost:3000
- **Scheduler Service**: http://localhost:3001
- **Worker Service 1**: http://localhost:3002
- **Worker Service 2**: http://localhost:3004
- **WebSocket Service**: http://localhost:3003
- **RabbitMQ Management**: http://localhost:15672 (username: \`admin\`, password: \`admin\`)
- **Elasticsearch**: http://localhost:9200
- **Kibana**: http://localhost:5601
- **Redis**: localhost:6379

### 6. სისტემის გამორთვა

```bash
docker compose down
```

მონაცემების სრულად წაშლა (ყველა volume):

```bash
docker compose down -v
```

## როგორ შევცვალოთ X (ჩანაწერების რაოდენობა) და Y (სიჩქარე წუთში)

### 1. Default მნიშვნელობების შეცვლა

\`.env\` ფაილში შეცვალეთ:

```bash

# X - ჩანაწერების რაოდენობა (default: 100)

DEFAULT_X_RECORDS=100

# Y - ჩანაწერების რაოდენობა წუთში (default: 60)

DEFAULT_Y_RATE_PER_MINUTE=60
```

შემდეგ გადაატვირთეთ სერვისები:

```bash
docker compose restart api-gateway
```

### 2. Frontend-ის საშუალებით (რეკომენდირებული)

1. გახსენით browser-ში http://localhost:4200
2. "New Job" ფორმაში შეიყვანეთ:
   - **Total Records (X)**: ჩანაწერების რაოდენობა (მაგ: 1000)
   - **Records Per Minute (Y)**: სიჩქარე (მაგ: 120)
3. დააჭირეთ "Start Job" ღილაკს

არსებული Job-ის სიჩქარის შეცვლისთვის Dashboard-ზე დააჭირეთ სასურველ Jobs მის დეტალურ გვერდზე გადასასვლელად. "Update Processing Speed" სექციაში შეიყვანეთ ახალი სიჩქარე. დააჭირეთ "Update Speed" ღილაკს.

შეგიძლიათ ერთდროულად რამდენიმე სამუშაო (Job) გაუშვათ. თითოეული მათგანი დამოუკიდებლად დამუშავდება და გამოჩნდება Dashboard-ზე.

### 3. API-ს საშუალებით (curl)

ახალი job-ის შექმნა:

```bash
curl -X POST http://localhost:3000/api/jobs \\
-H "Content-Type: application/json" \\
-d '{
"totalRecords": 1000,
"recordsPerMinute": 120
}'
```


არსებული job-ის სიჩქარის შეცვლა:

```bash
curl -X PATCH http://localhost:3000/api/jobs/{jobId} \\
-H "Content-Type: application/json" \\
-d '{
"recordsPerMinute": 200
}'
```


# როგორ დავაკვირდეთ მონაცემების მიმოცვლას

სისტემის მუშაობის შესამოწმებლად და იმის სანახავად, თუ როგორ მოძრაობს მონაცემები კომპონენტებს შორის, შეგიძლიათ გამოიყენოთ RabbitMQ-ს, Kibana-სა (Elasticsearch-ისთვის) და Redis-ის UI ინსტრუმენტები.

1. RabbitMQ-ში დაკვირვება

მისამართი: http://localhost:15672 (user: admin, pass: admin)

RabbitMQ-ს მართვის პანელი გაძლევთ საშუალებას, რეალურ დროში დააკვირდეთ შეტყობინებების ნაკადს.

    Queues (რიგები): გადადით "Queues" ტაბზე. აქ ნახავთ ორ მთავარ რიგს:

        job_queue: სადაც api-gateway-დან იგზავნება საწყისი ბრძანება სამუშაოს შექმნის შესახებ.

        record_processing_queue: სადაც scheduler-service-ი აგზავნის ცალკეულ ჩანაწერებს დასამუშავებლად.

    დამუშავების სიჩქარე: აირჩიეთ record_processing_queue. გვერდის ბოლოში, გრაფიკებზე, თქვენ შეგიძლიათ დააკვირდეთ "Message rates" სექციას. "Deliver (get)" გრაფიკი გიჩვენებთ, რა სიჩქარით ამუშავებენ Worker-ები ჩანაწერებს წამში. ეს არის თქვენ მიერ მითითებული Y პარამეტრის რეალური ასახვა.

2. Elasticsearch-ში დაკვირვება (Kibana-ს საშუალებით)

მისამართი: http://localhost:5601

Kibana არის UI Elasticsearch-ისთვის, სადაც შეგიძლიათ ნახოთ ყველა შენახული (დამუშავებული) ჩანაწერი.

    Data View-ს შექმნა:

        გახსენით მენიუ (მარცხენა ზედა კუთხე) და გადადით Analytics -> Discover.

        თუ პირველად შედიხართ, დააჭირეთ "Create data view".

        Index pattern ველში ჩაწერეთ processed-records.

        Timestamp field ველში აირჩიეთ processedAt.

        დააჭირეთ "Create data view".

    მონაცემების ნახვა:

        Data View-ს შექმნის შემდეგ, თქვენ დაინახავთ ყველა დამუშავებული ჩანაწერის სიას რეალურ დროში.

        დააჭირეთ "Refresh" ღილაკს, რათა განაახლოთ სია და ნახოთ ახლად დამატებული ჩანაწერები. თითოეული ჩანაწერის გახსნით შეგიძლიათ დეტალური ინფორმაციის ნახვა (რომელმა Worker-მა დაამუშავა, რა დრო დასჭირდა და ა.შ.).

3. Redis-ში დაკვირვება

Redis-ში მონაცემების სანახავად რეკომენდირებულია გრაფიკული ხელსაწყოს (მაგ. RedisInsight) გამოყენება.

    დაკავშირება: დაუკავშირდით თქვენს ლოკალურ Redis-ს (localhost:6379).

    Key Browser: გახსენით Key Browser.

    დაკვირვება: აქ შეგიძლიათ რეალურ დროში დააკვირდეთ:

        job:{jobId}:config და job:{jobId}:processedCount გასაღებებს, რომ ნახოთ სამუშაოს მიმდინარე სტატუსი და დამუშავებული ჩანაწერების რაოდენობა.

        scheduled_records გასაღებს (რომელიც არის Sorted Set). აქ ნახავთ, თუ როგორ ამატებს scheduler-service-ი ჩანაწერებს მომავლის დროის ნიშნულებით და როგორ ქრება ისინი სიიდან, როგორც კი მათი დამუშავების დრო მოვა.

# რა ტესტები ჩავატაროთ შედეგის შესამოწმებლად

## 1. ფუნქციონალურობის ტესტები

### ტესტი #1: Job-ის შექმნა და დამუშავება

```bash

#### Job-ის შექმნა

curl -X POST http://localhost:3000/api/jobs \\
-H "Content-Type: application/json" \\
-d '{"totalRecords": 100, "recordsPerMinute": 60}'

პასუხში მიიღებთ jobId-ს, მაგალითად:

{"jobId": "123e4567-e89b-12d3-a456-426614174000", ...}

#### Job-ის სტატუსის შემოწმება

curl http://localhost:3000/api/jobs/{jobId}/status
```

**მოსალოდნელი შედეგი**: სტატუსი უნდა იყოს \`processing\`, შემდეგ \`completed\`

### ტესტი #2: სიჩქარის შეცვლა რეალურ დროში

```bash

####Job-ის შექმნა ნელი სიჩქარით

curl -X POST http://localhost:3000/api/jobs \\
-H "Content-Type: application/json" \\
-d '{"totalRecords": 500, "recordsPerMinute": 30}'

#### 5 წამის შემდეგ, გაზარდეთ სიჩქარე

curl -X PATCH http://localhost:3000/api/jobs/{jobId} \\
-H "Content-Type: application/json" \\
-d '{"recordsPerMinute": 300}'
```

**მოსალოდნელი შედეგი**: პროგრესი უნდა დაჩქარდეს

## 2. Crash Tests

ამ ტესტების მიზანია იმის დემონსტრირება, რომ სისტემა მდგრადია, შეუძლია ავტომატურად აღდგეს და არ კარგავს მონაცემებს რომელიმე საკვანძო კომპონენტის მოულოდნელი გათიშვისას. ტესტირების ზოგადი პროცესი ყველა სერვისისთვის იდენტურია:

1. დაიწყეთ ახალი სამუშაო (Job).
2. სანამ პროცესი მიმდინარეობს, ტერმინალიდან მომენტალურად გააჩერეთ სასურველი კონტეინერი ბრძანებით: docker compose stop -t 0 service_name.
3. დააკვირდით მოსალოდნელ შეფერხებას.
4. ხელახლა ჩართეთ კონტეინერი: docker compose start service_name.
5. დარწმუნდით, რომ სისტემამ მუშაობა ავტომატურად განაახლა და სამუშაო კორექტულად დაასრულა.

### Worker სერვისები (worker-service)

    გაჩერება: docker compose stop -t 0 worker-service-1 worker-service-2

    დაკვირვება: Frontend-ზე პროგრესი ჩერდება. RabbitMQ-ს record_processing_queue-ში გროვდება დაუმუშავებელი შეტყობინებები.

    აღდგენა: ჩართვის შემდეგ, Worker-ები მომენტალურად იწყებენ დაგროვილი შეტყობინებების დამუშავებას, პროცესი გრძელდება და არცერთი ჩანაწერი არ იკარგება (Elasticsearch-ში შეიძლება გადამოწმება)

### Redis

    გაჩერება: docker compose stop -t 0 redis

    დაკვირვება: scheduler-service ვეღარ უკავშირდება Redis-ს და წყვეტს ახალი ჩანაწერების RabbitMQ-ში გაგზავნას. სერვისების ლოგებში ჩნდება კავშირის შეცდომები.

    აღდგენა: ჩართვის შემდეგ, სერვისები ავტომატურად აღადგენენ კავშირს, Scheduler განაახლებს მუშაობას და პროცესი გრძელდება.

### RabbitMQ

    გაჩერება: docker compose stop -t 0 rabbitmq

    დაკვირვება: ჩანაწერების მიმოცვლა სრულად ჩერდება. როგორც scheduler-service, ისე worker-service კარგავს კავშირს და ლოგებში წერს შეცდომებს.

    აღდგენა: ჩართვის შემდეგ, ყველა სერვისი აღადგენს კავშირს, შეტყობინებების ნაკადი განახლდება და სისტემა მუშაობას აგრძელებს.

### API Gateway (api-gateway)

    გაჩერება: docker compose stop -t 0 api-gateway

    დაკვირვება: Frontend-იდან შეუძლებელი ხდება ახალი სამუშაოს შექმნა ან არსებულის სტატუსის განახლება. ფონურ რეჟიმში დაწყებული პროცესები კი გრძელდება.

    აღდგენა: ჩართვის შემდეგ, Frontend-ი კვლავ ფუნქციონალური ხდება. გვერდის განახლებისას გამოჩნდება იმ სამუშაოების აქტუალური პროგრესი, რომლებიც მუშაობდა.

## 3. RabbitMQ მდგრადობის ტესტის შედეგები

ეს ტესტი ამოწმებს, თუ როგორ უმკლავდება სისტემა RabbitMQ-ს მოულოდნელ გათიშვას ჩანაწერების დამუშავების პროცესში და არის თუ არა დაკარგული მონაცემები.

### ტესტის აღწერა

**სამუშაოს კონფიგურაცია:**

- სულ ჩანაწერები: 1,000
- საწყისი დამუშავების სიჩქარე: 50 ჩანაწერი/წუთში
- მოგვიანებით გაზრდილი: 500 ჩანაწერი/წუთამდე

**ტესტის ნაბიჯები:**

1. დაიწყო 1,000 ჩანაწერის დამუშავება
2. RabbitMQ გაითიშა, როცა მხოლოდ 4 ჩანაწერი იყო დამუშავებული
3. რამდენიმე წამის შემდეგ RabbitMQ ხელახლა ჩაირთო
4. დამუშავების პროცესი მონიტორინგში იყო დასრულებამდე

### ტესტის შედეგები

**საბოლოო მაჩვენებლები:**

- **მოსალოდნელი ჩანაწერები:** 1,000
- **დამუშავებული ჩანაწერები (API):** 1,000 ✓
- **ჩანაწერები Elasticsearch-ში:** 1,000 ✓
- **უნიკალური ჩანაწერების ID-ები:** 1,000 ✓
- **შეტყობინებები RabbitMQ რიგებში:** 0 ✓
- **დაკარგული ჩანაწერები:** **0** ✓

### როგორ მოახერხა სისტემამ ავარიის დაძლევა

1. **გაჩერების გამოვლენა** (RabbitMQ-ს გათიშვისას):
   - Worker სერვისებმა აღმოაჩინეს: `CONNECTION_FORCED - broker forced connection closure with reason 'shutdown'`
   - ლოგებში გაჩნდა: `Disconnected from RMQ. Trying to reconnect.`

2. **აღდგენის მექანიზმების გააქტიურება**:
   - **"გაჭედილი" ჩანაწერების აღდგენა**: Scheduler სერვისის აღდგენის მექანიზმმა (რომელიც მუშაობს ყოველ 5 წამში) აღმოაჩინა ჩანაწერები, რომლებიც "გაიჭედა" `sent` ან `processing` მდგომარეობაში
   - მრავალი ჩანაწერი (22-46) მონიშნულ იქნა როგორც გაჭედილი და ავტომატურად აღდგა
   - მაგალითი ლოგიდან: `Recovered stuck record e046d2e6-280c-4f15-ac1a-dc3a1a7c2818:23 (was stuck for 13s)`

3. **ავტომატური ხელახალი კავშირი**:
   - Worker სერვისებმა სცადეს RabbitMQ-სთან ხელახალი დაკავშირება
   - RabbitMQ-ს ონლაინზე დაბრუნების შემდეგ, კავშირი აღდგა
   - დამუშავების პროცესი უწყვეტად გაგრძელდა

4. **შეტყობინების დადასტურების დაცვა**:
   - შეტყობინებები დასტურდება (ACK) მხოლოდ წარმატებული დამუშავების შემდეგ
   - დაუდასტურებელი შეტყობინებები დარჩა Worker-ების prefetch ბუფერებში გათიშვის დროს
   - ხელახალი გაშვების შემდეგ, ეს შეტყობინებები ან ხელახლა დამუშავდა ან აღდგა "გაჭედილი ჩანაწერების" სისტემის მეშვეობით

### მთავარი მდგრადობის მახასიათებლები

1. **გრძელვადიანი რიგები (Durable Queues)**: რიგები რჩება RabbitMQ-ს გადატვირთვის შემდეგაც (`rabbitmq-data` volume)

2. **ხელით დადასტურება (Manual Acknowledgment)**: შეტყობინებები მოითხოვს ექსპლიციტურ ACK-ს წარმატებული დამუშავების შემდეგ (`noAck: false`)

3. **Prefetch რაოდენობა**: Worker-ებს შეუძლიათ შეინახონ მაქსიმუმ 10 დაუდასტურებელი შეტყობინება

4. **"გაჭედილი" ჩანაწერების აღდგენა**: Scheduler სერვისი ყოველ 5 წამში ამოწმებს შუალედურ მდგომარეობაში გაჭედილ ჩანაწერებს

5. **ავტომატური ხელახალი კავშირი**: NestJS მიკროსერვისები ავტომატურად ცდილობენ RabbitMQ-სთან ხელახალ დაკავშირებას

6. **გამეორების ლოგიკა (Retry Logic)**: წარუმატებელი შეტყობინებები ერთხელ ხელახლა დგება რიგში, ხოლო მეორე წარუმატებლობის შემდეგ იგზავნება DLQ-ში (Dead Letter Queue)

### დასკვნა

**სისტემა მდგრადია RabbitMQ-ს გადატვირთვების მიმართ!**
შემდეგი კომბინაცია:

- გრძელვადიანი რიგები მუდმივი შენახვით,
- შეტყობინების ხელით დადასტურება,
- "გაჭედილი" ჩანაწერების აღდგენის მექანიზმი,
- ავტომატური ხელახალი კავშირის ლოგიკა

...უზრუნველყოფს, რომ **არცერთი ჩანაწერი არ იკარგება** მაშინაც კი, როდესაც RabbitMQ გაითიშება აქტიური დამუშავების დროს. სისტემა უმკლავდება ავარიას და აგრძელებს დამუშავებას RabbitMQ-ს ონლაინზე დაბრუნების შემდეგ.
